{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-69122e2e2690>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import os, types\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def __iter__(self): return 0\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "#import ImputingValues as t\n",
    "%matplotlib inline\n",
    "data_path = 'C:/Users/ruchi/OneDrive/projects/data/worldBank_waste/city_level_data_0_0.csv'\n",
    "df_city = pd.read_csv(data_path )\n",
    "df_city.describe(include='all')\n",
    "#df_city = df_city.dropna(thresh=3, axis=1)\n",
    "columns_name_indices = ['iso3c', 'region_id', 'country_name', 'income_id', 'city_name', 'total_msw_total_msw_generated_tons_year', 'population_population_number_of_people']\n",
    "predict_columns_name_indices = ['iso3c', 'region_id', 'country_name', 'income_id', 'city_name', 'population_population_number_of_people']\n",
    "#choose only those cities whose msw generation is reported\n",
    "df_city = df_city[df_city['total_msw_total_msw_generated_tons_year'].notna()]\n",
    "df_city['total_msw_total_msw_generated_tons_year'] = pd.to_numeric(df_city['total_msw_total_msw_generated_tons_year'], errors='coerce')\n",
    "df_city = df_city.set_index(columns_name_indices)\n",
    "df_city.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#print(input_df.head)#['population_population_number_of_people'].value_counts(bins = 4))#.plot.bar()#\n",
    "    \n",
    "#grouped = input_df.groupby(levels)#.value_counts#filter(like='composition').plot.bar(stacked=True, rot=75).legend(bbox_to_anchor=(1.04,1), loc=\"upper left\") \n",
    "#grouped_occurences = grouped.size().to_frame('occurences')#.reset_index()\n",
    "#grouped_occurences.unstack().plot(kind='bar', stacked=True)#.plot.bar(stacked=True)\n",
    "#print(grouped_occurences)\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.show()\n",
    "    \n",
    "#for name, group in grouped:        \n",
    "#print(\"NAME\",name)\n",
    "#print(group)#grouped.get_group(name).index.get_level_values(levels[2]).value_counts(bins = 4).plot.bar()#axs[row])\n",
    "#plt.show()\n",
    "#plt.xticks(rotation=90)\n",
    "#plt.show()\n",
    "\n",
    "grouped = df_city.groupby('income_id')#.value_counts#filter(like='composition').plot.bar(stacked=True, rot=75).legend(bbox_to_anchor=(1.04,1), loc=\"upper left\") \n",
    "for name, group in grouped:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group column data by the information it provides and name the groups \n",
    "\n",
    "informal_impact_df = df_city.filter(like='informal').dropna(axis=0,how='all')\n",
    "informal_impact_df.name = 'informal_impact_df'\n",
    "composition_df = df_city.filter(like='composition').dropna(axis=0,how='all')\n",
    "composition_df.name = 'composition_df'\n",
    "separation_df = df_city.filter(like='separation').dropna(axis=0,how='all')\n",
    "separation_df.name = 'separation_df'\n",
    "transportation_df = df_city.filter(like='transportation').dropna(axis=0,how='all')\n",
    "transportation_df.name = 'transportation_df'\n",
    "collection_cost_df = df_city.filter(like='collection_cost').dropna(axis=0,how='all')\n",
    "collection_cost_df.name = 'collection_cost_df'\n",
    "collection_cover_df = df_city.filter(like='collection_cover').dropna(axis=0,how='all')\n",
    "collection_cover_df.name = 'collection_cover_df'\n",
    "management_df = df_city.filter(like='management_cost').dropna(axis=0,how='all')\n",
    "management_df.name = 'management_df'\n",
    "disposal_df = df_city.filter(like='disposal').dropna(axis=0,how='all')\n",
    "disposal_df.name = 'disposal_df'\n",
    "treatment_df = df_city.filter(like='treatment').dropna(axis=0,how='all')\n",
    "treatment_df.name = 'treatment_df'\n",
    "energy_df = df_city.filter(like='energy').dropna(axis=0,how='all')\n",
    "energy_df.name = 'energy_df'\n",
    "framework_df = df_city.filter(like='framework').dropna(axis=0,how='all')\n",
    "framework_df.name = 'framework_df'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rectify_data(input_df):\n",
    "\n",
    "    if len(input_df.select_dtypes(exclude=['object']).columns.tolist()):\n",
    "        print(\"Cleaning numerical data\")\n",
    "        if input_df.name == 'informal_impact_df':\n",
    "            for index in input_df['informal_sector_total_waste_pickers_number'].where(input_df['informal_sector_total_waste_pickers_number']>0):\n",
    "                print(input_df['informal_sector_child_waste_pickers_number'])\n",
    "                input_df.iloc[index]['informal_sector_child_waste_pickers_percent'] = 100*(input_df.iloc[index]['informal_sector_child_waste_pickers_number']/input_df.iloc[index]['informal_sector_total_waste_pickers_number'])\n",
    "                input_df.iloc[index]['informal_sector_female_waste_pickers_percent'] = 100*(input_df.iloc[index]['informal_sector_female_waste_pickers_number']/input_df.iloc[index]['informal_sector_total_waste_pickers_number'])\n",
    "                input_df = input_df.drop(columns=['informal_sector_child_waste_pickers_number', 'informal_sector_female_waste_pickers_number'])    \n",
    "\n",
    "    for column in input_df.select_dtypes(include=['object']).columns.tolist():\n",
    "        print(\"Cleaning categorical data\", column)\n",
    "        if input_df[column].str.isnumeric().any():\n",
    "            print(\"Column has numbers in string\")\n",
    "            input_df[column] = pd.to_numeric(input_df[column], errors='coerce')\n",
    "        else:\n",
    "            print(\"Column has string data\")\n",
    "            value_list = ['yes', 'no ', 'door', 'curbside', 'centralized-drop-off', 'mulitple', 'other', 'flat fee per bussiness']\n",
    "            for value in value_list:\n",
    "                input_df.loc[input_df[column].str.contains(value, na=False, case=False), column] = value\n",
    "    print(\"Data rectified\")\n",
    "    return input_df\n",
    "\n",
    "def fill_num_data(input_df, levels, num_cols):\n",
    "    \n",
    "    for column in num_cols:\n",
    "        print(\"Fill missing numerical data column \",column, \"with mean of \", levels[0])\n",
    "        input_df[column] = input_df[column].fillna(input_df.groupby(levels[0])[column].transform('mean'))\n",
    "        if input_df[column].isnull().any():\n",
    "            print(\"Fill missing numerical data column \",column, \"with mean of \", levels[1])\n",
    "            input_df[column] = input_df[column].fillna(input_df.groupby(levels[1])[column].transform('mean'))\n",
    "        if input_df[column].isnull().any():\n",
    "            print(\"Fill missing numerical data column \",column, \"with mean of country_name\")\n",
    "            input_df[column] = input_df[column].fillna(input_df.groupby('country_name')[column].transform('mean'))\n",
    "        if input_df[column].isnull().any():\n",
    "            print(\"cannot fill missing numerical data. Drop row\")\n",
    "            input_df = input_df[input_df[column].notnull()]\n",
    "    return input_df\n",
    "def create_dummy_df(df, cat_cols, dummy_na):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - pandas dataframe with categorical variables you want to dummy\n",
    "    cat_cols - list of strings that are associated with names of the categorical columns\n",
    "    dummy_na - Bool holding whether you want to dummy NA vals of categorical columns or not\n",
    "    \n",
    "    OUTPUT:\n",
    "    df - a new dataframe that has the following characteristics:\n",
    "            1. contains all columns that were not specified as categorical\n",
    "            2. removes all the original columns in cat_cols\n",
    "            3. dummy columns for each of the categorical columns in cat_cols\n",
    "            4. if dummy_na is True - it also contains dummy columns for the NaN values\n",
    "            5. Use a prefix of the column name with an underscore (_) for separating \n",
    "    '''\n",
    "    for col in  cat_cols:\n",
    "        try:\n",
    "            # for each cat add dummy var, drop original column\n",
    "            df = pd.concat([df.drop(col, axis=1), pd.get_dummies(df[col], prefix=col, prefix_sep='_', drop_first=True, dummy_na=dummy_na)], axis=1)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    return df\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reportedData_distribution(input_df):\n",
    "    reported_count = {column:input_df[column].dropna(how='all').shape[0] for column in  input_df.columns}\n",
    "    plt.bar(range(len(reported_count)), list(reported_count.values()), tick_label=list(reported_count.keys()))\n",
    "    lgd = plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('country_count')\n",
    "    plt.savefig(input_df.name+'reportedData_vs_countryCount.png', format='png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    print(\"*********END OF REPORTED DATA***********\")\n",
    "    \n",
    "    \n",
    "def get_stacked_distribution(input_df, levels,cluster_levels):\n",
    "\n",
    "    input_df2 = input_df.reset_index().groupby(levels).agg(    \n",
    "    count_country =('country_name', \"count\"),# Get count of country for each group\n",
    "    mean_population =(cluster_levels[1], 'mean'),# Get mean of the population for each group\n",
    "    mean_msw =(cluster_levels[0], 'mean')# Get mean of the msw for each group\n",
    "    )    \n",
    "    \n",
    "    print('mean population')\n",
    "    input_df2['mean_population'].unstack().plot(kind='bar', stacked=False)#\n",
    "    lgd = plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('mean population')\n",
    "    plt.savefig(input_df.name+'_'+levels[0]+'_'+levels[1]+'_vs_meanPopulation.png', format='png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    print('mean msw')\n",
    "    input_df2['mean_msw'].unstack().plot(kind='bar', stacked=False)#\n",
    "    lgd = plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('mean msw')\n",
    "    plt.savefig(input_df.name+'_'+levels[0]+'_'+levels[1]+'_vs_meanMSW.png', format='png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    #print('count_country', input_df2['count_country'].unstack())\n",
    "    input_df2['count_country'].unstack().plot(kind='bar', stacked=True)#\n",
    "    lgd = plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "    plt.ylabel('country_count')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(input_df.name+'_'+levels[0]+'_'+levels[1]+'_vs_countryCount.png', format='png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    num_cols = input_df.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    if num_cols:\n",
    "        print(\"numerical data present. Plot mean and then get clusters\")\n",
    "        \n",
    "        for level in levels:\n",
    "            input_df3 = input_df.groupby(level).agg(['mean'])\n",
    "            #print(input_df3)\n",
    "            input_df3.plot(kind='bar', stacked=False)#\n",
    "            lgd = plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.ylabel('all_numerical_columns_mean')\n",
    "            plt.savefig(input_df.name+'_'+level+'_'+'_all_numerical_columns_mean.png', format='png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "            #plt.show()\n",
    "            \n",
    "    else:\n",
    "        print(\"For categorical data. Cannot get mean. Get clusters of \")\n",
    "        \n",
    "    #for column in input_df.select_dtypes(exclude=['object']).columns.tolist():#input_df.columns:\n",
    "        #print(column)\n",
    "        #input_df3[column].unstack().plot(kind='bar', stacked=False)#\n",
    "        #plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "        #plt.xticks(rotation=90)\n",
    "        #plt.show()\n",
    "    \n",
    "    \n",
    "    #input_df.plot.line(rot=90)\n",
    "    print(\"*********END OF STACKED DISTRIBUTION***********\")    \n",
    "    \n",
    "\n",
    "def plot_grouped_df(grouped_df, ax,  x, y, cmap = plt.cm.coolwarm):\n",
    "\n",
    "    colors = cmap(np.linspace(0.5, 1, len(grouped_df)))\n",
    "    c=np.array([colors])\n",
    "    for i, (name,group) in enumerate(grouped_df):\n",
    "        group.plot(ax=ax,\n",
    "                   kind='scatter', \n",
    "                   x=x, y=y,\n",
    "                   color=colors[i],\n",
    "                   label = name)\n",
    "def get_clusters(input_df, levels,cluster_level):\n",
    "    \n",
    "    plt_col = 1\n",
    "    num_cols = input_df.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    plt_row_num = len(num_cols)#len(levels)* \n",
    "    cat_cols = input_df.select_dtypes(include=['object']).columns.tolist()\n",
    "    plt_row_cat = len(cat_cols)\n",
    "    \n",
    "    count = 1\n",
    "    for column in num_cols:       \n",
    "        for level in levels:\n",
    "            print(\"Numerical Data: \",column, level)\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(10,2))        \n",
    "            plot_grouped_df(input_df.reset_index().groupby(level),ax, x=column, y=cluster_level)\n",
    "            #plt.subplot(plt_row,1,count)\n",
    "            lgd = plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "            count = count +1\n",
    "            plt.savefig(input_df.name+'_'+level+'_'+column+'.png', format='png', bbox_extra_artists=(lgd,), bbox_inches='tight')   \n",
    "            #plt.show()\n",
    "             \n",
    "    count = 1\n",
    "    for column in cat_cols:        \n",
    "        for level in levels:\n",
    "            print(\"Categorical Data:\", column, level, cluster_level)\n",
    "            sns.catplot(x=level, y=cluster_level, hue=column, kind=\"boxen\", data=input_df.reset_index())\n",
    "            #input_df.reset_index().groupby(level)[column].plot.bar()\n",
    "            lgd = plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "            count = count +1\n",
    "            plt.savefig(input_df.name+'_'+level+'_'+column+'.png', format='png', bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "            #plt.show()\n",
    "    print(\"*********END OF CLUSTERS***********\")    \n",
    "\n",
    "\n",
    "    return 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_relation(df):\n",
    "\n",
    "    #Only use quant variables and drop any rows with missing values    \n",
    "    num_cols = df.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    plt_row_num = len(num_cols)#len(levels)* \n",
    "    cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    plt_row_cat = len(cat_cols)\n",
    "    input_dummy_df = df\n",
    "    #print(input_dummy_df)\n",
    "    if plt_row_num:\n",
    "        input_dummy_df = fill_num_data(df, levels, num_cols)\n",
    "    if plt_row_cat:\n",
    "        input_dummy_df = create_dummy_df(input_dummy_df, cat_cols, dummy_na=True)\n",
    "    \n",
    "\n",
    "    input_df = input_dummy_df.reset_index()#   \n",
    "    input_df = input_df[input_df['total_msw_total_msw_generated_tons_year'].notna()]\n",
    "    input_df = input_df.set_index(predict_columns_name_indices)\n",
    "\n",
    "    #Split into explanatory and response variables\n",
    "    y = input_df['total_msw_total_msw_generated_tons_year']\n",
    "    X = input_df.drop(['total_msw_total_msw_generated_tons_year'], axis=1)\n",
    "    \n",
    "    print(\"Check if x or y is nan or inf\")\n",
    "    print(np.any(np.isinf(X)))\n",
    "    print(np.any(np.isinf(y)))\n",
    "    print(np.any(np.isnan(X)))\n",
    "    print(np.any(np.isnan(y)))\n",
    "    print(X.columns[X.isnull().any()].tolist(), X.isnull().sum().sum())\n",
    "    print(y.isnull().any(), y.isnull().sum().sum())\n",
    "    #print(X[X.columns[X.isnull().any()].tolist()])\n",
    "    print(pd.isnull(y).any().nonzero()[0])#np.where(y.isna())#y[y.isnull().any()])\n",
    "    #print(\"CHeck for categorical data\", input_dummy_df.select_dtypes(include=['object']).columns.tolist())\n",
    "    #Split into train and test\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .50, random_state=42) \n",
    "    print(X_train.size, X_test.size)\n",
    "    lm_model = LinearRegression(normalize=False) # Instantiate\n",
    "    lm_model.fit(X_train, y_train) #Fit\n",
    "        \n",
    "    #Predict and score the model\n",
    "    y_test_preds = lm_model.predict(X_test) \n",
    "    print(\"The r-squared score for your model was {} on {} values.\".format(r2_score(y_test, y_test_preds), len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning numerical data\n",
      "iso3c  region_id  country_name  income_id  city_name   total_msw_total_msw_generated_tons_year  population_population_number_of_people\n",
      "AFG    SAS        Afghanistan   LIC        Jalalabad   58914.45                                 326585.0                                   NaN\n",
      "                                           Kabul       1989250.00                               3700000.0                                  NaN\n",
      "                                           HiratÂ      91644.70                                 337000.0                                   NaN\n",
      "ARM    ECS        Armenia       UMC        Vanadzor    23596.97                                 86199.0                                    NaN\n",
      "BGD    SAS        Bangladesh    LMC        Patuakhali  5220.00                                  65000.0                                    NaN\n",
      "                                                                                                                                          ... \n",
      "TUN    MEA        Tunisia       LMC        Sousse      70000.00                                 170000.0                                   NaN\n",
      "URY    LCN        Uruguay       HIC        Montevideo  481800.00                                1319108.0                                  NaN\n",
      "VUT    EAS        Vanuatu       LMC        Port Vila   27000.00                                 44039.0                                    NaN\n",
      "XKX    ECS        Kosovo        LMC        Gjilan      27000.00                                 90015.0                                   40.0\n",
      "ZMB    SSF        Zambia        LMC        Lusaka      530000.00                                1719000.0                                  NaN\n",
      "Name: informal_sector_child_waste_pickers_number, Length: 63, dtype: float64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot index by location index with a non-integer key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2ddcf1922d4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalysis_topic_dfList\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m#print(df)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrectify_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;31m#print(df)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m#get_reportedData_distribution(df)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-d7ea336dce4b>\u001b[0m in \u001b[0;36mrectify_data\u001b[1;34m(input_df)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'informal_sector_total_waste_pickers_number'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'informal_sector_total_waste_pickers_number'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'informal_sector_child_waste_pickers_number'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                 \u001b[0minput_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'informal_sector_child_waste_pickers_percent'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'informal_sector_child_waste_pickers_number'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0minput_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'informal_sector_total_waste_pickers_number'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m                 \u001b[0minput_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'informal_sector_female_waste_pickers_percent'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'informal_sector_female_waste_pickers_number'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0minput_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'informal_sector_total_waste_pickers_number'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[0minput_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'informal_sector_child_waste_pickers_number'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'informal_sector_female_waste_pickers_number'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    877\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1491\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1492\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1493\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot index by location index with a non-integer key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1495\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot index by location index with a non-integer key"
     ]
    }
   ],
   "source": [
    "levels = ['income_id', 'region_id']#,\n",
    "cluster_levels = ['total_msw_total_msw_generated_tons_year', 'population_population_number_of_people']\n",
    "analysis_topic_dfList = [#informal_impact_df, \n",
    "                         #framework_df,\n",
    "                         composition_df, \n",
    "                         separation_df, \n",
    "                         transportation_df, \n",
    "                         collection_cost_df,\n",
    "                         collection_cover_df,\n",
    "                         management_df, \n",
    "                         disposal_df, \n",
    "                         treatment_df, \n",
    "                         energy_df \n",
    "                        ]\n",
    "\n",
    "for df in analysis_topic_dfList:\n",
    "    #print(df)\n",
    "    df = rectify_data(df)\n",
    "    #print(df)\n",
    "    get_reportedData_distribution(df)\n",
    "    get_stacked_distribution(df, levels, cluster_levels)\n",
    "    get_clusters(df, levels,cluster_levels[0])\n",
    "    check_relation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
